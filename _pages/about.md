---
permalink: /
title: "About Me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

Hi, my name is Weize Chen (ÈôàÁ∫¨Ê≥Ω(Áé∞)/ÈôàÊöêÊ≥Ω(Êóß)), and I am currently a 4th-year PhD student at Tsinghua University, advised by [Prof. Zhiyuan Liu](https://nlp.csai.tsinghua.edu.cn/~lzy/). I am also a proud member of the [THUNLP](https://github.com/THUNLP/) group. I earned my bachelor‚Äôs degree from the Department of Computer Science and Technology at Tsinghua University.

My research focuses on **natural language processing (NLP)** and **machine learning (ML)**, with a particular emphasis on improving the performance and efficiency of **agent systems** and **large language model (LLM)** systems.

Specifically, my research interests lie in:

- **(Multi-)Agent Systems**: Designing and implementing agent systems for LLMs and MLLMs to enhance performance. My work also explores improving agent communication and cooperation for more effective collaboration.
- **Reinforcement Learning**: Investigating the mechanism of LLM RL, and pushing the limit of LLM RL.

Before ChatGPT, my research interests included **neural ODE/SDE**, **hyperbolic neural networks**, and **knowledge graphs**. These experiences continue to inform my perspective on advancing AI.

# News

- **[2025-09]** ‚ú® The **[DIET](https://arxiv.org/abs/2505.19217)** has been accepted at **NeurIPS 2025**! We integrate an on-the-fly difficulty estimation to RL to mitigate the overthinking problem of the reasoning LLM.

- **[2025-09]** ü•≥ We have just released a **[blog](https://husky-morocco-f72.notion.site/From-f-x-and-g-x-to-f-g-x-LLMs-Learn-New-Skills-in-RL-by-Composing-Old-Ones-2499aba4486f802c8108e76a12af3020?source=copy_link)** showing that RL do teach the LLM new generalizable compositional skill, and these skills are transferrable across domains. Check it out!

- **[2025-02]** üéâ **[IoA](https://arxiv.org/abs/2407.07061)** has been accepted as a **spotlight** at **ICLR 2025**!

- **[2024-10]** üöÄ **[Optima](https://chenweize1998.github.io/optima-project-page/)** (*Optimizing the effectiveness and efficiency of multi-agent systems*) is now released! Our paper demonstrates that iterative training for multi-agent systems significantly enhances performance and efficiency, achieving up to **90% reduction in inference tokens** while delivering superior performance. Moreover, with fewer inference tokens, **we establish a better inference scaling law**!

- **[2024-07]** üöÄ **[IoA](https://arxiv.org/abs/2407.07061)** (*Internet of Agents*) has been released! We introduce the concept of connecting heterogeneous and distributed agents via the Internet and present a [prototype implementation](https://github.com/OpenBMB/IoA) functioning as an instant-messaging app for agents. Our experiments on complex agent tasks, embodied agents, and retrieval-augmented generation (RAG) demonstrate the effectiveness of IoA.

- **[2024-01]** üéâ **[AgentVerse](https://arxiv.org/abs/2308.10848)** has been accepted to **ICLR 2024**! See you in Vienna! Also take a try at our [GitHub repo](https://github.com/OpenBMB/AgentVerse), which now has **more than 4k stars**!

# Highlighted Publications:
Please refer to [publication](/publications) for the full list.

**The Overthinker's DIET: Cutting Token Calories with DIfficulty-AwarE Training**<br>
*Weize Chen\*, Jiarui Yuan\*, Tailin Jin, Ning Ding, Huimin Chen, Zhiyuan Liu, Maosong Sun*<br>
*NeurIPS 2025* [[paper](https://arxiv.org/pdf/2505.19217)] [[code](https://github.com/thunlp/DIET)]

**From f(x) and g(x) to f(g(x)): LLMs Learn New Skills in RL by Composing Old Ones**<br>
*Lifan Yuan\*,¬†Weize Chen\*, Yuchen Zhang, Ganqu Cui, Hanbin Wang, Ziming You, Ning Ding, Zhiyuan Liu, Maosong Sun, Hao Peng*<br>
*Blog Post* [[blog](https://husky-morocco-f72.notion.site/From-f-x-and-g-x-to-f-g-x-LLMs-Learn-New-Skills-in-RL-by-Composing-Old-Ones-2499aba4486f802c8108e76a12af3020)] [[tweet](https://x.com/lifan__yuan/status/1963662222602723673)]

**Optima: Optimizing Effectiveness and Efficiency for LLM-Based Multi-Agent System**<br>
*Weize Chen\*, Jiarui Yuan\*, Chen Qian, Cheng Yang, Zhiyuan Liu, Maosong Sun*<br>
*ALC 2025 Findings* [[project page](https://chenweize1998.github.io/optima-project-page)] [[pdf](https://arxiv.org/abs/2410.08115)] [[code](https://github.com/thunlp/Optima)]

**Internet of Agents: Weaving a Web of Heterogeneous Agents for Collaborative Intelligence**<br>
*Weize Chen\*, Ziming You\*, Ran Li\*, Yitong Guan\*, Chen Qian, Chenyang Zhao, Cheng Yang, Ruobing Xie, Zhiyuan Liu, Maosong Sun*<br>
*ICLR 2025 **Spotlight*** [[pdf](https://arxiv.org/pdf/2407.07061)] [[code](https://github.com/OpenBMB/IoA)]

**AgentVerse: Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors**<br>
*Weize Chen\*, Yusheng Su\*, Jingwei Zuo, Cheng Yang, Chenfei Yuan, Chi-Min Chan, Heyang Yu, Yaxi Lu, Yi-Hsin Hung, Chen Qian, Yujia Qin, Xin Cong, Ruobing Xie, Zhiyuan Liu, Maosong Sun, Jie Zhou*<br>
*ICLR 2024* [[pdf](https://arxiv.org/pdf/2308.10848)] [[code](https://github.com/OpenBMB/AgentVerse)]

**ChatEval: Towards Better LLM-based Evaluators through Multi-Agent Debate**<br>
*Chi-Min Chan, Weize Chen, Yusheng Su, Jianxuan Yu, Wei Xue, Shanghang Zhang, Jie Fu, Zhiyuan Liu*<br>
*ICLR 2024* [[pdf](https://arxiv.org/pdf/2308.07201)] [[code](https://github.com/thunlp/ChatEval)]

**Fully Hyperbolic Neural Networks**<br>
*Weize Chen\*, Xu Han\*, Yankai Lin, Hexu Zhao, Zhiyuan Liu, Peng Li, Maosong Sun, Jie Zhou*<br>
*ACL 2022* [[pdf](https://arxiv.org/abs/2105.14686)] [[code](https://github.com/chenweize1998/fully-hyperbolic-nn)]

**Quantifying Similarity between Relations with Fact Distribution**<br>
*Weize Chen, Hao Zhu, Xu Han, Zhiyuan Liu, Maosong Sun*<br>
*ACL 2019 **Oral*** [[pdf](https://aclanthology.org/P19-1278.pdf)] [[code](https://github.com/thunlp/relation-similarity)]
